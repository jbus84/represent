#!/usr/bin/env python3
"""
Verify Row-Level Classification Demo

This script demonstrates that the classification system classifies EACH ROW
(each price movement) into a class, not entire files.

It shows:
1. How global thresholds are calculated once
2. How each row gets its own classification label
3. Sample output showing row-by-row classification
"""

import sys
from pathlib import Path
import polars as pl

# Add represent package to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from represent import (
    calculate_global_thresholds,
    process_dbn_to_classified_parquets
)


def verify_row_level_classification():
    """Verify that classification works at the row level."""
    
    print("üîç VERIFYING ROW-LEVEL CLASSIFICATION")
    print("=" * 60)
    
    # Data source
    data_directory = Path("/Users/danielfisher/data/databento/AUDUSD-micro")
    output_directory = Path("/Users/danielfisher/repositories/represent/examples/classification_analysis/outputs/verification")
    output_directory.mkdir(parents=True, exist_ok=True)
    
    if not data_directory.exists():
        print(f"‚ùå Data directory not found: {data_directory}")
        return False
    
    # Find DBN files
    dbn_files = sorted([f for f in data_directory.glob("*.dbn*") if f.is_file()])
    
    if not dbn_files:
        print("‚ùå No DBN files found")
        return False
    
    print(f"üìä Found {len(dbn_files)} DBN files")
    
    # Step 1: Calculate Global Thresholds
    print("\nüéØ STEP 1: Calculate Global Thresholds for ALL Rows")
    print("-" * 50)
    
    try:
        # Use first 5 files for quick demo
        sample_fraction = min(5 / len(dbn_files), 1.0)
        
        global_thresholds = calculate_global_thresholds(
            data_directory=data_directory,
            currency="AUDUSD",
            nbins=13,
            sample_fraction=sample_fraction,
            max_samples_per_file=3000,  # Small for quick demo
            verbose=True
        )
        
        print("\n‚úÖ Global thresholds calculated:")
        print(f"   üìä Based on {global_thresholds.sample_size:,} individual price movements")
        print(f"   üìä From {global_thresholds.files_analyzed} files")
        
        # Show some boundaries
        boundaries = global_thresholds.quantile_boundaries
        print("\nüéØ Sample Threshold Boundaries:")
        for i in range(min(3, len(boundaries)-1)):
            print(f"   Rows with movement ‚â§ {boundaries[i]:.2f} Œºpips ‚Üí Class {i}")
        print("   ...")
        print("   (13 classes total, each row gets classified individually)")
        
    except Exception as e:
        print(f"‚ùå Failed: {e}")
        return False
    
    # Step 2: Process One File to Show Row-Level Classification
    print("\nüîÑ STEP 2: Process One File - Each Row Gets Classified")
    print("-" * 50)
    
    try:
        # Process one file
        test_file = dbn_files[0]
        print(f"Processing: {test_file.name}")
        
        results = process_dbn_to_classified_parquets(
            dbn_path=test_file,
            output_dir=output_directory,
            currency="AUDUSD",
            global_thresholds=global_thresholds,  # Same thresholds for ALL rows
            features=["volume"],
            min_symbol_samples=100,  # Lower for demo
            verbose=False
        )
        
        print("\n‚úÖ Processing complete:")
        print(f"   üìä Generated {results['symbols_processed']} symbol files")
        print(f"   üìä Classified {results['total_classified_samples']:,} individual rows")
        print("   üéØ Each row got its own classification label (0-12)")
        
    except Exception as e:
        print(f"‚ùå Processing failed: {e}")
        return False
    
    # Step 3: Examine the Output to Show Row-Level Structure
    print("\nüìä STEP 3: Examine Output - Verify Row-Level Classification")
    print("-" * 50)
    
    try:
        # Find generated files
        classified_files = list(output_directory.glob("*_classified.parquet"))
        
        if not classified_files:
            print("‚ùå No classified files found")
            return False
        
        # Load and examine one file
        sample_file = classified_files[0]
        df = pl.read_parquet(sample_file)
        
        symbol = sample_file.stem.split('_')[1]
        print(f"üìÑ Examining: {sample_file.name}")
        print(f"üìä Symbol: {symbol}")
        print(f"üìä Total rows: {len(df):,}")
        
        if 'classification_label' not in df.columns:
            print("‚ùå No classification_label column found")
            return False
        
        # Show sample rows
        sample_rows = df.select([
            'ts_event', 'ask_px_00', 'bid_px_00', 'price_movement', 'classification_label'
        ]).head(10)
        
        print("\nüìã SAMPLE ROWS (showing row-by-row classification):")
        print("=" * 80)
        print(sample_rows)
        
        # Show classification distribution
        labels = df['classification_label'].to_numpy()
        unique_labels, counts = pl.Series(labels).value_counts().sort('classification_label').to_numpy().T
        
        print("\nüìà CLASSIFICATION DISTRIBUTION (per row):")
        print("-" * 40)
        for label, count in zip(unique_labels, counts):
            percentage = (count / len(df)) * 100
            print(f"   Class {label:2d}: {count:6,} rows ({percentage:5.1f}%)")
        
        print("\nüéØ KEY INSIGHTS:")
        print("‚úÖ Each row in the dataset has its own classification_label")
        print("‚úÖ Labels are based on individual price movements (price_movement column)")
        print("‚úÖ Same global thresholds applied to every single row")
        print("‚úÖ NOT classifying entire files - classifying each price movement!")
        
        # Verify price movement to classification mapping
        print("\nüîç PRICE MOVEMENT ‚Üí CLASSIFICATION MAPPING:")
        print("-" * 50)
        
        # Sample some rows to show the mapping
        sample_movements = df.select(['price_movement', 'classification_label']).head(5)
        boundaries = global_thresholds.quantile_boundaries
        
        for row in sample_movements.to_dicts():
            movement = row['price_movement']
            label = row['classification_label']
            
            if movement is not None and label is not None:
                # Find which boundary this falls into
                if label < len(boundaries) - 1:
                    threshold = boundaries[label]
                    print(f"   Movement: {movement:7.2f} Œºpips ‚Üí Class {label} (‚â§ {threshold:.2f})")
        
        print("\nüéâ VERIFICATION COMPLETE!")
        print("‚úÖ System correctly classifies EACH ROW individually")
        print("‚úÖ Each price movement gets its own classification label") 
        print("‚úÖ Global thresholds ensure consistency across ALL rows in ALL files")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Verification failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("üîç ROW-LEVEL CLASSIFICATION VERIFICATION")
    print("=" * 70)
    print("Verifying that each row gets its own classification label")
    print("=" * 70)
    
    success = verify_row_level_classification()
    
    if success:
        print("\nüéâ VERIFICATION SUCCESSFUL!")
        print("‚úÖ Confirmed: Each row gets classified individually")
        print("‚úÖ Global thresholds applied consistently to every row")
        print("‚úÖ NOT classifying files - classifying price movements!")
    else:
        print("\n‚ùå VERIFICATION FAILED")
        print("Check output above for details")